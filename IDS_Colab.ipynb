{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üõ°Ô∏è Autonomous Explainable Intrusion Detection System\n",
        "\n",
        "This notebook runs the complete IDS pipeline on Google Colab with GPU acceleration.\n",
        "\n",
        "**Steps:**\n",
        "1. Install dependencies\n",
        "2. Upload project files\n",
        "3. Download dataset\n",
        "4. Train model (1 epoch)\n",
        "5. Process samples\n",
        "\n",
        "**Note:** Ollama LLM will be disabled on Colab (requires local installation)"
      ],
      "metadata": {
        "id": "header"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üì¶ Step 1: Install Dependencies"
      ],
      "metadata": {
        "id": "install"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q tensorflow scikit-learn pandas numpy matplotlib seaborn shap kagglehub langchain langchain-core"
      ],
      "metadata": {
        "id": "install_deps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìÅ Step 2: Upload Project Files\n",
        "\n",
        "**Option A: Upload ZIP file**\n",
        "- Zip your project folder on your Mac\n",
        "- Upload and extract here\n",
        "\n",
        "**Option B: Clone from GitHub** (if you have it there)"
      ],
      "metadata": {
        "id": "upload"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Option A: Upload and extract ZIP\n",
        "from google.colab import files\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "print(\"Upload your ids-explainable-agent.zip file:\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Extract\n",
        "for filename in uploaded.keys():\n",
        "    if filename.endswith('.zip'):\n",
        "        with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
        "            zip_ref.extractall('.')\n",
        "        print(f\"‚úì Extracted {filename}\")\n",
        "\n",
        "# Change to project directory\n",
        "%cd ids-explainable-agent"
      ],
      "metadata": {
        "id": "upload_files"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîß Step 3: Configure for Colab (Disable Ollama)"
      ],
      "metadata": {
        "id": "config"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check GPU availability\n",
        "import tensorflow as tf\n",
        "print(\"GPU Available:\", tf.config.list_physical_devices('GPU'))\n",
        "print(\"TensorFlow version:\", tf.__version__)"
      ],
      "metadata": {
        "id": "check_gpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üöÄ Step 4: Run the Pipeline\n",
        "\n",
        "This will:\n",
        "- Download dataset (~1.6GB)\n",
        "- Train for 1 epoch (~5-10 minutes on GPU)\n",
        "- Process 5 samples\n",
        "- Save results"
      ],
      "metadata": {
        "id": "run"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run pipeline without Ollama (not available on Colab)\n",
        "!python pipeline.py --samples 5 --retrain --no-ollama"
      ],
      "metadata": {
        "id": "run_pipeline"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìä Step 5: View Results"
      ],
      "metadata": {
        "id": "results"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import glob\n",
        "\n",
        "# Find the latest results file\n",
        "result_files = glob.glob('ids_results_*.json')\n",
        "if result_files:\n",
        "    latest_result = sorted(result_files)[-1]\n",
        "    print(f\"üìÑ Loading results from: {latest_result}\\n\")\n",
        "    \n",
        "    with open(latest_result, 'r') as f:\n",
        "        results = json.load(f)\n",
        "    \n",
        "    # Display results\n",
        "    for i, result in enumerate(results):\n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(f\"SAMPLE {i+1}\")\n",
        "        print(f\"{'='*70}\")\n",
        "        print(f\"True Label: {result['true_label']}\")\n",
        "        print(f\"Predicted: {result['attack_type']}\")\n",
        "        print(f\"Confidence: {result['confidence']:.4f}\")\n",
        "        print(f\"Risk Score: {result['risk_score']:.4f}\")\n",
        "        print(f\"Severity: {result['severity']}\")\n",
        "        print(f\"Agent Decision: {result['agent_decision']}\")\n",
        "        print(f\"\\nTop Features:\")\n",
        "        for feat in result['top_features'][:3]:\n",
        "            print(f\"  - {feat['name']}: {feat['shap_value']:.4f}\")\n",
        "else:\n",
        "    print(\"No results found. Run the pipeline first.\")"
      ],
      "metadata": {
        "id": "view_results"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üíæ Step 6: Download Results and Model"
      ],
      "metadata": {
        "id": "download"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import glob\n",
        "\n",
        "# Download results JSON\n",
        "result_files = glob.glob('ids_results_*.json')\n",
        "if result_files:\n",
        "    for f in result_files:\n",
        "        files.download(f)\n",
        "        print(f\"‚úì Downloaded {f}\")\n",
        "\n",
        "# Download trained model\n",
        "if os.path.exists('saved_models/ids_cnn.keras'):\n",
        "    files.download('saved_models/ids_cnn.keras')\n",
        "    print(\"‚úì Downloaded trained model\")\n",
        "\n",
        "# Download training history plot\n",
        "if os.path.exists('training_history.png'):\n",
        "    files.download('training_history.png')\n",
        "    print(\"‚úì Downloaded training history plot\")"
      ],
      "metadata": {
        "id": "download_results"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìà Step 7: View Training History"
      ],
      "metadata": {
        "id": "plot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "import os\n",
        "\n",
        "if os.path.exists('training_history.png'):\n",
        "    display(Image('training_history.png'))\n",
        "else:\n",
        "    print(\"Training history plot not found.\")"
      ],
      "metadata": {
        "id": "show_plot"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
